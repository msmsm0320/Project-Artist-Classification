{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7482ccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15958965417122060732\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5726273536\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12502619072871558825\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "forced-partition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of X_train:  5911\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def cutout(image, label, probability=0.5):\n",
    "    if np.random.rand() < probability:\n",
    "        h, w = image.shape[:2]\n",
    "        size = np.random.randint(w // 2)\n",
    "        x1 = np.random.randint(w)\n",
    "        y1 = np.random.randint(h)\n",
    "        x2 = np.clip(x1 + size, 0, w)\n",
    "        y2 = np.clip(y1 + size, 0, h)\n",
    "        image[y1:y2, x1:x2, :] = np.random.rand(y2 - y1, x2 - x1, 3)\n",
    "    return image, label\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "label_encoder = LabelEncoder()\n",
    "artist_df = df.copy()\n",
    "artist_train = label_encoder.fit_transform(df['artist'].values)\n",
    "\n",
    "\n",
    "artist_df['num'] = artist_train\n",
    "artist_df = artist_df.drop('id', axis=1)\n",
    "artist_df = artist_df.drop('img_path', axis=1)\n",
    "\n",
    "\n",
    "artist_df.set_index('num', inplace=True)\n",
    "artist_df = artist_df.sort_index()\n",
    "\n",
    "\n",
    "artist_test_dic = artist_df['artist'].to_dict()\n",
    "\n",
    "\n",
    "# 데이터 노이즈 수정\n",
    "df.loc[df['id'] == 3896, 'artist'] = 'Titian'\n",
    "df.loc[df['id'] == 3986, 'artist'] = 'Alfred Sisley'\n",
    "\n",
    "X_train = df\n",
    "\n",
    "#X_train, X_val, y_train, y_val = train_test_split(df, df['artist'].values, test_size=0.1)\n",
    "\n",
    "print(\"Number of X_train: \", len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7346e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5320 validated image filenames belonging to 50 classes.\n",
      "Found 591 validated image filenames belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', classes=pd.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(244,244,3), input_tensor=None, pooling=None)\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "predictions = Dense(50, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "LearningRate = 1e-3\n",
    "\n",
    "optimizer = Adam(learning_rate=LearningRate)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "CP = ModelCheckpoint(filepath='model/' +\n",
    "                     'ResNet50-Sigmoid-{epoch:03d}-{loss:.4f}-{val_loss:.4f}.hdf5',\n",
    "                     monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=0.00005)\n",
    "CALLBACK = [CP, LR]\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "\n",
    "DATAGEN_TRAIN = ImageDataGenerator(\n",
    "    rescale=1/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    data_format=\"channels_last\",\n",
    "    validation_split=0.10\n",
    ")\n",
    "\n",
    "\n",
    "TRAIN_GENERATOR = DATAGEN_TRAIN.flow_from_dataframe(\n",
    "    dataframe=X_train, x_col='img_path', y_col='artist',\n",
    "    target_size=(244, 244), \n",
    "    class_mode='categorical',\n",
    "    batch_size=32, shuffle=True,\n",
    "    subset=\"training\",\n",
    "    preprocessing_function=cutout\n",
    ")\n",
    "\n",
    "VALID_GENERATOR = DATAGEN_TRAIN.flow_from_dataframe(\n",
    "    dataframe=X_train, x_col='img_path', y_col='artist',\n",
    "    target_size=(244, 244), \n",
    "    class_mode='categorical',\n",
    "    batch_size=32, shuffle=True,\n",
    "    subset=\"validation\",\n",
    "    preprocessing_function=cutout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6006be2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 117s 663ms/step - loss: 5.2329 - acc: 0.1842 - val_loss: 18.5790 - val_acc: 0.0372\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 63s 375ms/step - loss: 4.1067 - acc: 0.2669 - val_loss: 8.1499 - val_acc: 0.0355\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 63s 378ms/step - loss: 3.6257 - acc: 0.3305 - val_loss: 5.2258 - val_acc: 0.0169\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 63s 375ms/step - loss: 3.2453 - acc: 0.3805 - val_loss: 5.6478 - val_acc: 0.0389\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 62s 372ms/step - loss: 2.9904 - acc: 0.4182 - val_loss: 4.8331 - val_acc: 0.0745\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 63s 374ms/step - loss: 2.7409 - acc: 0.4474 - val_loss: 2.6913 - val_acc: 0.3113\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 62s 370ms/step - loss: 2.5095 - acc: 0.4962 - val_loss: 3.1515 - val_acc: 0.2572\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 71s 423ms/step - loss: 2.3512 - acc: 0.5148 - val_loss: 3.1540 - val_acc: 0.2876\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 65s 387ms/step - loss: 2.2536 - acc: 0.5284 - val_loss: 3.6232 - val_acc: 0.2030\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 65s 387ms/step - loss: 2.1133 - acc: 0.5573 - val_loss: 3.2750 - val_acc: 0.3638\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 63s 374ms/step - loss: 2.0068 - acc: 0.5759 - val_loss: 3.0010 - val_acc: 0.2876\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 63s 373ms/step - loss: 1.8735 - acc: 0.5981 - val_loss: 2.4741 - val_acc: 0.3875\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 63s 374ms/step - loss: 1.7104 - acc: 0.6265 - val_loss: 3.4038 - val_acc: 0.3046\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 63s 374ms/step - loss: 1.6586 - acc: 0.6342 - val_loss: 3.8671 - val_acc: 0.2893\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 63s 374ms/step - loss: 1.5891 - acc: 0.6427 - val_loss: 3.6794 - val_acc: 0.2318\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 63s 376ms/step - loss: 1.4180 - acc: 0.6758 - val_loss: 5.1508 - val_acc: 0.2792\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 63s 376ms/step - loss: 1.3735 - acc: 0.6808 - val_loss: 2.8012 - val_acc: 0.4281\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 63s 379ms/step - loss: 1.3295 - acc: 0.6966 - val_loss: 5.3874 - val_acc: 0.2707\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 63s 378ms/step - loss: 1.1732 - acc: 0.7203 - val_loss: 2.7118 - val_acc: 0.4179\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 63s 375ms/step - loss: 1.0953 - acc: 0.7310 - val_loss: 3.2065 - val_acc: 0.3824\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 63s 375ms/step - loss: 1.0072 - acc: 0.7489 - val_loss: 2.3608 - val_acc: 0.4772\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 63s 375ms/step - loss: 1.0486 - acc: 0.7491 - val_loss: 3.3964 - val_acc: 0.3519\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 63s 375ms/step - loss: 0.9320 - acc: 0.7665 - val_loss: 4.6680 - val_acc: 0.2453\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 63s 374ms/step - loss: 0.8708 - acc: 0.7763 - val_loss: 9.1870 - val_acc: 0.2961\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 63s 375ms/step - loss: 0.8181 - acc: 0.7991 - val_loss: 4.3164 - val_acc: 0.3249\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 63s 377ms/step - loss: 0.8628 - acc: 0.7805 - val_loss: 4.7998 - val_acc: 0.3029\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 63s 376ms/step - loss: 0.6974 - acc: 0.8184 - val_loss: 3.1369 - val_acc: 0.4044\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 63s 377ms/step - loss: 0.6244 - acc: 0.8325 - val_loss: 3.6928 - val_acc: 0.3875\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 63s 378ms/step - loss: 0.6318 - acc: 0.8368 - val_loss: 6.2760 - val_acc: 0.2589\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 63s 377ms/step - loss: 0.9063 - acc: 0.7833 - val_loss: 2.6865 - val_acc: 0.4839\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 63s 377ms/step - loss: 0.6212 - acc: 0.8344 - val_loss: 3.0271 - val_acc: 0.4518\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 63s 378ms/step - loss: 0.5429 - acc: 0.8526 - val_loss: 3.2997 - val_acc: 0.3858\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 63s 376ms/step - loss: 0.5792 - acc: 0.8462 - val_loss: 5.9224 - val_acc: 0.2640\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 63s 378ms/step - loss: 0.5393 - acc: 0.8485 - val_loss: 4.9882 - val_acc: 0.2826\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 63s 376ms/step - loss: 0.5613 - acc: 0.8498 - val_loss: 2.8449 - val_acc: 0.4095\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 63s 374ms/step - loss: 0.4689 - acc: 0.8699 - val_loss: 5.5196 - val_acc: 0.2386\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 63s 374ms/step - loss: 0.4877 - acc: 0.8716 - val_loss: 5.0815 - val_acc: 0.3147\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 63s 378ms/step - loss: 0.5996 - acc: 0.8500 - val_loss: 2.9395 - val_acc: 0.4162\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 63s 377ms/step - loss: 0.4150 - acc: 0.8831 - val_loss: 2.6359 - val_acc: 0.4738\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 63s 376ms/step - loss: 0.3614 - acc: 0.8930 - val_loss: 2.4961 - val_acc: 0.5398\n",
      "Epoch 41/200\n",
      "167/167 [==============================] - 63s 377ms/step - loss: 0.3705 - acc: 0.8953 - val_loss: 4.5619 - val_acc: 0.3875\n",
      "Epoch 42/200\n",
      "167/167 [==============================] - 63s 377ms/step - loss: 0.4363 - acc: 0.8831 - val_loss: 3.4450 - val_acc: 0.3824\n",
      "Epoch 43/200\n",
      "167/167 [==============================] - 63s 376ms/step - loss: 0.3866 - acc: 0.8915 - val_loss: 3.9110 - val_acc: 0.3486\n",
      "Epoch 44/200\n",
      "167/167 [==============================] - 63s 377ms/step - loss: 0.3881 - acc: 0.8883 - val_loss: 3.3059 - val_acc: 0.3858\n",
      "Epoch 45/200\n",
      "167/167 [==============================] - 63s 378ms/step - loss: 0.3180 - acc: 0.9100 - val_loss: 4.7073 - val_acc: 0.3536\n",
      "Epoch 46/200\n",
      "167/167 [==============================] - 63s 379ms/step - loss: 0.4299 - acc: 0.8806 - val_loss: 5.0392 - val_acc: 0.2978\n",
      "Epoch 47/200\n",
      "167/167 [==============================] - 63s 377ms/step - loss: 0.4476 - acc: 0.8799 - val_loss: 6.3687 - val_acc: 0.3080\n",
      "Epoch 48/200\n",
      "167/167 [==============================] - 63s 374ms/step - loss: 0.3691 - acc: 0.9053 - val_loss: 3.1619 - val_acc: 0.4602\n",
      "Epoch 49/200\n",
      "167/167 [==============================] - 63s 377ms/step - loss: 0.3288 - acc: 0.9120 - val_loss: 4.3353 - val_acc: 0.3283\n",
      "Epoch 50/200\n",
      "167/167 [==============================] - 63s 375ms/step - loss: 0.3478 - acc: 0.9071 - val_loss: 4.2913 - val_acc: 0.3401\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    TRAIN_GENERATOR,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping],\n",
    "    shuffle=True,\n",
    "    validation_data=VALID_GENERATOR,\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0413e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12670 validated image filenames.\n",
      "396/396 [==============================] - 134s 337ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "DATAGEN_TEST = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    data_format=\"channels_last\"\n",
    ")\n",
    "\n",
    "TEST_GENERATOR = DATAGEN_TEST.flow_from_dataframe(\n",
    "    dataframe=X_test,\n",
    "    x_col='img_path',\n",
    "    y_col=None,\n",
    "    target_size=(244, 244),\n",
    "    color_mode='rgb',\n",
    "    class_mode=None,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "TEST_Prediction = model.predict(TEST_GENERATOR, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd90c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_num = np.argmax(TEST_Prediction, axis=1)\n",
    "num_list = pd.DataFrame(artist_num, columns=['artist'])\n",
    "\n",
    "artist_name = []\n",
    "for i in num_list['artist']:\n",
    "    artist_name.append(artist_test_dic[i])\n",
    "\n",
    "last_ans = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "last_ans.rename(columns={'artist':'artist_name'}, inplace=True)\n",
    "\n",
    "last_ans['artist'] = artist_name\n",
    "last_ans.drop('artist_name', axis=1, inplace=True)\n",
    "\n",
    "last_ans.to_csv(\"ResNet50_200_ES.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a35aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
